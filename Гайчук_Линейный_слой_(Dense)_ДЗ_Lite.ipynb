{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d_qXycKuUA51"
      },
      "source": [
        "### Задание"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aUMmCXubUHEb"
      },
      "source": [
        "Создайте систему компьютерного зрения, которая будет определять тип геометрической фигуры. Используя подготовленную базу и шаблон ноутбука проведите серию экспериментов по перебору гиперпараметров нейронной сети, распознающей три категории изображений (треугольник, круг, квадрат).\n",
        "\n",
        "1. Поменяйте количество нейронов в сети, используя следующие значения:\n",
        "\n",
        "- один слой 10 нейронов\n",
        "- один слой 100 нейронов\n",
        "- один слой 5000 нейронов.\n",
        "\n",
        "2. Поменяйте активационную функцию в скрытых слоях с `relu` на `linear`.\n",
        "3. Поменяйте размеры batch_size:\n",
        "- 10\n",
        "- 100\n",
        "- 1000\n",
        "\n",
        "4. Выведите на экран получившиеся точности.\n",
        "\n",
        "Всего должно получиться 18 комбинаций указанных параметров.\n",
        "\n",
        "Создайте сравнительную таблицу по результатам проведенных тестов."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2zDFM0apy8-R"
      },
      "source": [
        "# Подключение класса для создания нейронной сети прямого распространения\n",
        "from tensorflow.keras.models import Sequential\n",
        "# Подключение класса для создания полносвязного слоя\n",
        "from tensorflow.keras.layers import Dense\n",
        "# Подключение оптимизатора\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "# Подключение утилит для to_categorical\n",
        "from tensorflow.keras import utils\n",
        "# Подключение библиотеки для загрузки изображений\n",
        "from tensorflow.keras.preprocessing import image\n",
        "# Подключение библиотеки для работы с массивами\n",
        "import numpy as np\n",
        "# Подключение библиотек для отрисовки изображений\n",
        "import matplotlib.pyplot as plt\n",
        "# Подключение модуля для работы с файлами\n",
        "import os\n",
        "# Вывод изображения в ноутбуке, а не в консоли или файле\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yK5nGKwvcXKD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a7b97bc7-6c24-4fa8-cdb8-3a915d6d9ff0"
      },
      "source": [
        "# Загрузка датасета из облака\n",
        "import gdown\n",
        "gdown.download('https://storage.yandexcloud.net/aiueducation/Content/base/l3/hw_light.zip', None, quiet=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'hw_light.zip'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VCcXAah-y1Uy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d0a86cb-359d-40e8-ca70-cfdc15224dee"
      },
      "source": [
        "# Распаковываем архив hw_light.zip в папку hw_light\n",
        "!unzip -q hw_light.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "replace hw_light/0/1.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "replace hw_light/0/10.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "replace hw_light/0/100.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "replace hw_light/0/101.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "replace hw_light/0/102.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "replace hw_light/0/11.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "replace hw_light/0/12.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "replace hw_light/0/13.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "replace hw_light/0/14.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "replace hw_light/0/15.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "replace hw_light/0/16.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "replace hw_light/0/17.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "replace hw_light/0/18.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "replace hw_light/0/19.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: \n",
            "error:  invalid response [{ENTER}]\n",
            "replace hw_light/0/19.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "replace hw_light/0/2.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "replace hw_light/0/20.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "replace hw_light/0/21.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "replace hw_light/0/22.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "replace hw_light/0/23.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "replace hw_light/0/24.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace hw_light/0/25.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace hw_light/0/26.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace hw_light/0/27.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace hw_light/0/28.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: a\n",
            "error:  invalid response [a]\n",
            "replace hw_light/0/28.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: a\n",
            "error:  invalid response [a]\n",
            "replace hw_light/0/28.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Hp0WpKAzEji",
        "outputId": "1b1d83de-c48f-4829-8150-1083e51f5ea0"
      },
      "source": [
        "# Загрузка и подготовка данных\n",
        "data_dir = \"./hw_light\"\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    data_dir,\n",
        "    target_size=(64, 64),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    data_dir,\n",
        "    target_size=(64, 64),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "# Гиперпараметры для экспериментов\n",
        "neurons_options = [10, 100, 5000]\n",
        "activation_options = ['relu', 'linear']\n",
        "batch_sizes = [10, 100, 1000]\n",
        "\n",
        "results = []\n",
        "\n",
        "# Перебор всех комбинаций\n",
        "for neurons in neurons_options:\n",
        "    for activation in activation_options:\n",
        "        for batch_size in batch_sizes:\n",
        "\n",
        "            # Создание модели\n",
        "            model = Sequential([\n",
        "                Flatten(input_shape=(64, 64, 3)),\n",
        "                Dense(neurons, activation=activation),\n",
        "                Dense(3, activation='softmax')\n",
        "            ])\n",
        "\n",
        "            model.compile(optimizer=Adam(),\n",
        "                          loss='categorical_crossentropy',\n",
        "                          metrics=['accuracy'])\n",
        "\n",
        "            # Обучение модели\n",
        "            history = model.fit(\n",
        "                train_generator,\n",
        "                epochs=5,\n",
        "                batch_size=batch_size,\n",
        "                validation_data=test_generator,\n",
        "                verbose=0\n",
        "            )\n",
        "\n",
        "            # Оценка модели\n",
        "            _, test_acc = model.evaluate(test_generator, verbose=0)\n",
        "\n",
        "            # Сохранение результатов\n",
        "            results.append({\n",
        "                'Neurons': neurons,\n",
        "                'Activation': activation,\n",
        "                'Batch Size': batch_size,\n",
        "                'Accuracy': test_acc\n",
        "            })\n",
        "\n",
        "            print(f\"Neurons: {neurons}, Activation: {activation}, Batch Size: {batch_size}, Accuracy: {test_acc:.4f}\")\n",
        "\n",
        "# Создание таблицы результатов\n",
        "results_df = pd.DataFrame(results)\n",
        "print(results_df)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 302 images belonging to 3 classes.\n",
            "Found 302 images belonging to 3 classes.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Neurons: 10, Activation: relu, Batch Size: 10, Accuracy: 0.5464\n",
            "Neurons: 10, Activation: relu, Batch Size: 100, Accuracy: 0.3377\n",
            "Neurons: 10, Activation: relu, Batch Size: 1000, Accuracy: 0.6358\n",
            "Neurons: 10, Activation: linear, Batch Size: 10, Accuracy: 0.5166\n",
            "Neurons: 10, Activation: linear, Batch Size: 100, Accuracy: 0.8377\n",
            "Neurons: 10, Activation: linear, Batch Size: 1000, Accuracy: 0.7914\n",
            "Neurons: 100, Activation: relu, Batch Size: 10, Accuracy: 0.8245\n",
            "Neurons: 100, Activation: relu, Batch Size: 100, Accuracy: 0.7748\n",
            "Neurons: 100, Activation: relu, Batch Size: 1000, Accuracy: 0.7682\n",
            "Neurons: 100, Activation: linear, Batch Size: 10, Accuracy: 0.6821\n",
            "Neurons: 100, Activation: linear, Batch Size: 100, Accuracy: 0.8113\n",
            "Neurons: 100, Activation: linear, Batch Size: 1000, Accuracy: 0.6258\n",
            "Neurons: 5000, Activation: relu, Batch Size: 10, Accuracy: 0.7152\n",
            "Neurons: 5000, Activation: relu, Batch Size: 100, Accuracy: 0.6921\n",
            "Neurons: 5000, Activation: relu, Batch Size: 1000, Accuracy: 0.7781\n",
            "Neurons: 5000, Activation: linear, Batch Size: 10, Accuracy: 0.7351\n",
            "Neurons: 5000, Activation: linear, Batch Size: 100, Accuracy: 0.7483\n",
            "Neurons: 5000, Activation: linear, Batch Size: 1000, Accuracy: 0.8179\n",
            "    Neurons Activation  Batch Size  Accuracy\n",
            "0        10       relu          10  0.546358\n",
            "1        10       relu         100  0.337748\n",
            "2        10       relu        1000  0.635762\n",
            "3        10     linear          10  0.516556\n",
            "4        10     linear         100  0.837748\n",
            "5        10     linear        1000  0.791391\n",
            "6       100       relu          10  0.824503\n",
            "7       100       relu         100  0.774834\n",
            "8       100       relu        1000  0.768212\n",
            "9       100     linear          10  0.682119\n",
            "10      100     linear         100  0.811258\n",
            "11      100     linear        1000  0.625828\n",
            "12     5000       relu          10  0.715232\n",
            "13     5000       relu         100  0.692053\n",
            "14     5000       relu        1000  0.778146\n",
            "15     5000     linear          10  0.735099\n",
            "16     5000     linear         100  0.748344\n",
            "17     5000     linear        1000  0.817881\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dIUQD1_TgPVZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}